<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<meta http-equiv="X-UA-Compatible" content="ie=edge" />
		<title>audio-virtual</title>
		<style>
			body {
				background: #000;
				display: flex;
				flex-flow: column nowrap;
			}
			#wave {
				transform: scale(0.75);
			}
		</style>
	</head>
	<body>
		<span style="color: #fff"
			>Choose a voice file (.wav or .mp3) upload and see the effect， BTW you
			can modify my code to realize voice autoplay</span
		>
		<input type="file" id="download" />
		<canvas id="wave"></canvas>
		<script>
			window.onload = function () {
				window.AudioContext =
					window.AudioContext ||
					window.webkitAudioContext ||
					window.mozAudioContext ||
					window.msAudioContext;
				try {
					audioCtx = new AudioContext();
				} catch (e) {
					console.error(e);
				}
				function $(v, d) {
					d = d || document;
					return d.querySelector(v);
				}
				var STOP = true;
				var processor = null;
				var audioBufferSourceNode = null;
				var analyser = null;
				/** 决定了音频采样的数量，如果取 256 则为柱状图，越多其曲线越光滑 */
				var samplePoint = 256; // 采样数
				var dataStack = new Array(samplePoint).fill(0);
				function visualize(buffer) {
					audioBufferSourceNode = audioCtx.createBufferSource();
					/** 创建声源分析器 */
					analyser = audioCtx.createAnalyser();
					/** 创建控制音频音量的中间件 */
					var gainNode = audioCtx.createGain();
					// 把音源 buffer => 嵌入到 audio Ctx 中
					audioBufferSourceNode.buffer = buffer;
					/** 连接音量控制器 */
					audioBufferSourceNode.connect(gainNode);
					audioBufferSourceNode.connect(analyser);
					// 将声音连接到扬声器
					audioBufferSourceNode.connect(audioCtx.destination);
					// start 入参为时刻，即从什么时候开始播放
					audioBufferSourceNode.start(0);
					STOP = false;
					// 以线性的方式停止
					// gainNode.gain.linearRampToValueAtTime(0.001, audioCtx.currentTime + 1);
					// 以指数的方式停止, 在路由前5秒逐渐减少声音
					var rampTime = Math.min(
						audioCtx.currentTime - 0.08,
						audioCtx.currentTime
					);
					// gainNode.gain.exponentialRampToValueAtTime(0.001, rampTime);
					// 声音响起后，将分析器的信息传递给绘图引擎进行绘图
					drawSpectrum(analyser);
					audioBufferSourceNode.onended = function () {
						// audioBufferSourceNode.disconnect(analyser)
						// processor.disconnect(audioCtx.destination)
						// analyser.disconnect(processor)
						var a = new Array(samplePoint).fill(0);
						dataStack = a;
						console.log("dataStack", dataStack);
						setTimeout(function () {
							STOP = true;
						}, 100);
					};
				}
				function drawSpectrum(analyser) {
					/** 定义一个缓冲处理区 */
					processor = audioCtx.createScriptProcessor(4096, 1, 1);
					/** 将缓冲区和扬声器相连接 */
					processor.connect(audioCtx.destination);
					/** 将分析器将缓冲区相互连接 */
					analyser.connect(processor);
					// 快速傅立叶变换 Fast Fourier Transform | frequencyBinCount 为 FFT 的一半
					/* 定义一个 Uint8Array 字节流去接收分析后的数据 */
					var bufferLength = analyser.frequencyBinCount;
					var data = new Uint8Array(analyser.frequencyBinCount);
					processor.onaudioprocess = function () {
						analyser.getByteTimeDomainData(data);
						console.log("data", data);
						var step = Math.round(data.length / samplePoint);
						var stack = [];
						for (var i = 0; i < samplePoint; i++) {
							var value = data[i * step];
							stack.push(value);
						}
						dataStack = stack;
					};
				}
				var oFile = $("#download");
				var oFileContent = null;
				oFile.onchange = function () {
					if (!audioCtx) {
						return;
					}
					if (oFile.files.length !== 0) {
						oFileContent = oFile.files[0];
						oFileName = oFileContent.name;
						var fr = new FileReader();
						fr.readAsArrayBuffer(oFileContent);
						fr.onload = function (e) {
							var fileResult = e.target.result;
							/** 处理 音频文件解码 后的数据 */
							audioCtx.decodeAudioData(
								fileResult,
								function (buffer) {
									visualize(buffer);
								},
								function (e) {
									console.log("decode errrrrror!");
								}
							);
						};
					}
				};
				var ctxDocumentElement = $("#wave");
				var ctx = ctxDocumentElement.getContext("2d");
				var ctxRadius = 1000;
				ctxDocumentElement.width = ctxRadius;
				ctxDocumentElement.height = ctxRadius;
				ctxDocumentElement.style.width = ctxRadius + "px";
				ctxDocumentElement.style.height = ctxRadius + "px";
				// ctx.scale(ctxRatio, ctxRatio)
				var width2 = ctxRadius / 2;
				var height2 = ctxRadius / 2;
				var heightMax = height2 - 4;
				var R = width2 / 2;
				var arcX = width2;
				var arcY = height2;
				var arcStack = [];
				var M = Math;
				var PI = M.PI;
				var Cos = M.cos;
				var Sin = M.sin;
				// 创建离屏画布
				function createCanvas() {
					var oCanvas = document.createElement("canvas");
					oCanvas.width = ctxRadius;
					oCanvas.height = ctxRadius;
					oCanvas.style.width = ctxRadius + "px";
					oCanvas.style.height = ctxRadius + "px";
					return oCanvas;
				}
				// 颜色函数
				function RGB2Color(r, g, b) {
					return "#" + byte2Hex(r) + byte2Hex(g) + byte2Hex(b);
				}
				function byte2Hex(n) {
					var nybHexString = "0123456789ABCDEF";
					return (
						String(nybHexString.substr((n >> 4) & 0x0f, 1)) +
						nybHexString.substr(n & 0x0f, 1)
					);
				}
				function colorful(i) {
					var frequency = 0.05;
					red = Math.sin(frequency * i + 0) * 127 + 128;
					green = Math.sin(frequency * i + 2) * 127 + 128;
					blue = Math.sin(frequency * i + 4) * 127 + 128;
					return RGB2Color(red, green, blue);
				}
				function gapVar(gapLen) {
					var f = 0;
					var e = gapLen - 1;
					var result = [];
					return function () {
						result = [f, e];
						if (e - f <= 1) {
							f = 0;
							e = gapLen - 1;
						} else {
							++f;
							--e;
						}
						return result;
					};
				}
				var getVar = gapVar(256);
				var bgCanvas = createCanvas(); // 背景颜色画布
				var bgCtx = bgCanvas.getContext("2d");
				var voiceCanvas = createCanvas(); // 音频图画布
				var voiceCtx = voiceCanvas.getContext("2d");
				var colorCount = 16;
				var temp = 2; // 波高，越大，波峰越高
				function update() {
					// 以平均值作为基准
					var average = dataStack.reduce((p, n) => p + n) / samplePoint;
					ctx.clearRect(0, 0, ctxRadius, ctxRadius);
					voiceCtx.clearRect(0, 0, ctxRadius, ctxRadius);

					for (
						var i = -(PI / 2), k = 0;
						i <= -(PI / 2) + PI * 2;
						i += (2 * PI) / samplePoint, k++
					) {
						var x = width2 + R * Cos(i);
						var y = height2 + R * Sin(i);
						var rectWidth = 5;
						var rectHeight = (dataStack[k] - average) * temp;
						voiceCtx.save();
						voiceCtx.translate(x + rectWidth / 2, y);
						voiceCtx.rotate(PI / 2 + i);
						voiceCtx.beginPath();
						voiceCtx.rect(-rectWidth / 2, -rectHeight, rectWidth, rectHeight);
						voiceCtx.fillStyle = "#fff";
						voiceCtx.fill();
						voiceCtx.restore();
					}
					bgCtx.clearRect(0, 0, ctxRadius, ctxRadius);
					var grd = bgCtx.createLinearGradient(0, 0, ctxRadius, ctxRadius);
					var bit = getVar();
					grd.addColorStop(0, colorful(bit[0]));
					grd.addColorStop(1, colorful(bit[1]));
					bgCtx.fillStyle = grd;
					bgCtx.fillRect(0, 0, ctxRadius, ctxRadius);
					ctx.globalCompositeOperation = "source-over";
					ctx.drawImage(voiceCanvas, 0, 0);
					ctx.globalCompositeOperation = "source-in";
					ctx.drawImage(bgCanvas, 0, 0);
				}
				+(function render() {
					requestAnimationFrame(render);
					if (!STOP) {
						update();
					}
				})();
			};
		</script>
	</body>
</html>
